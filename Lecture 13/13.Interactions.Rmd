---
title: 'Lecture 13: Multiple Regression part III: Interactions'
author: "Zachary Marion"
date: "3/12/2018"
output: pdf_document
fontsize: 12pt 
geometry: margin=0.75in
---

```{r setup, include=FALSE}
library(knitr)
library(extrafont)
loadfonts()
setwd("~/Dropbox/BayesClass/2018 Class/Lecture 13")
knitr::opts_chunk$set(
  echo = TRUE,
  comment = NA,
  fig.align = "center",
  fig.height = 3,
  fig.width = 4
  )
```
\emph{* This lecture is based on chapter 7 of Statistical Rethinking by Richard McElreath.}

As always, we need to load some packages and set some options prior to running any models:

```{r stanPackages, echo=TRUE, message=FALSE, warning=FALSE, results='hide'}
library(rstan)
library(shinystan)
library(car)
library(xtable)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
source("../utilityFunctions.R")
```

\section*{Unique intercepts}

Another way to model categorical variables is to construct a vector of intercept parameters, one for each category and then use index variables. 
  
  * This is very similar to what we did earlier when we made hierarchical models.
```{r eval=FALSE}
data {
  int<lower=0> nObs;
  int<lower=0> nVar;      // no. vars
  vector[nObs] obs;
  int x[nObs];
  real<lower=0> aMu;      // mean of prior alpha
  real<lower=0> aSD;      // SD of prior alpha
  real<lower=0> sigmaSD;  // scale for sigma
}

parameters {
  vector[nVar] alpha;
  real<lower=0> sigma;
}

model {
  alpha ~ normal(aMu, aSD);
  sigma ~ cauchy(0, sigmaSD);
  {
    vector[nObs] mu;
    mu = alpha[x];
    
    obs ~ normal(mu, sigma);  
  }
}

```  
```{r engine = 'cat', engine.opts = list(file = "13.interceptMod.stan", lang = "stan"), echo=FALSE}
data {
  int<lower=0> nObs;
  int<lower=0> nVar;      // no. vars
  vector[nObs] obs;
  int x[nObs];
  real<lower=0> aMu;      // mean of prior alpha
  real<lower=0> aSD;      // SD of prior alpha
  real<lower=0> sigmaSD;  // scale for sigma
}

parameters {
  vector[nVar] alpha;
  real<lower=0> sigma;
}

model {
  alpha ~ normal(aMu, aSD);
  sigma ~ cauchy(0, sigmaSD);
  {
    vector[nObs] mu;
    mu = alpha[x];
    
    obs ~ normal(mu, sigma);  
  }
}

```

```{r}
milk <- read.csv("milkFull.csv")
unique(milk$clade)
```

```{r, message=FALSE, warning=FALSE, cache=TRUE, verbose=FALSE}

obs <- milk$kcal
x   <- as.integer(milk$clade)
nObs <- nrow(milk)
nVar <- max(x)
aMu <- 0.6         
aSD <- sigmaSD <- 10

dat <- list(nObs=nObs, nVar=nVar, obs=obs, x=x, aMu=aMu, aSD=aSD, 
  sigmaSD=sigmaSD)

intMod <- stan(file="13.interceptMod.stan", data=dat, iter=2000,
 chains=4, seed=867.5309)

round(summary(intMod, pars=c("alpha", "sigma"),  
  probs = c(0.025, 0.5, 0.975))$summary,2)
```

\section{Interactions}
The next example (from Nunn & Puga, 2011) is lame because it isn't ecological, but the thought process is nice nonetheless. The data consist of the gross domestic product (`GDP`) for a number of countries around the world in relation to geography (specifically ruggedness). 

We are going to focus on GDP comparisons between African countries and non-African countries (artificial I know). 
   
  * We will use the logarithm of GDP because wealth tends to be an exponential process and we are interested in the *magnitude* (i.e., wealth begets more wealth)
 
 * Terrain ruggedness (`rugged`) is often related to bad economies---at least outside of Africa. 
   
    + Here `rugged` is a Terrain Ruggedness Index that quantifies topographic heterogeneity of landscapes.
  
Let's read in the data and fit regression models to African vs non-African countries separately at first using the `13.uniMod.stan` model.    
```{r}
rugged <- read.csv("RuggedGDP.csv")
rugged <- rugged[order(rugged$rugged),]
afr <- rugged[rugged$africa == 1, ] # African dataset
nafr <- rugged[rugged$africa == 0, ] # non-African dataset
afr <- afr[order(afr$rugged),]
nafr <- nafr[order(nafr$rugged),]
```

```{r, message=FALSE, warning=FALSE, cache=TRUE, verbose=FALSE}
# African linear regression
afrDat <- list(nObs=nrow(afr), obs=log(afr$GDP), xvar=afr$rugged, aSD=20, 
   bSD=1, sigmaSD=10)

afrMod <- stan(file="13.uniMod.stan", data=afrDat, iter=2000,
 chains=4, seed=867.5309)
afrMu <- as.matrix(afrMod, "mu")

# NonAfrican linear regression
nafrDat <- list(nObs=nrow(nafr), obs=log(nafr$GDP), xvar=nafr$rugged, aSD=20, 
   bSD=1, sigmaSD=10)

nafrMod <- stan(file="13.uniMod.stan", data=nafrDat, iter=2000,
 chains=4, seed=867.5309)
nMu <- as.matrix(nafrMod, "mu")
```

```{r, fig.height=2.6, fig.width=7}
par(mar=c(3,3.2,0.1,0.5))
par(mfrow=c(1,2))

### AFRICA
# Mean & HDI 
afrHDI <- apply(afrMu,2, HDI, credMass=0.95)
afrMean <- colMeans(afrMu)

# Make an empty plot
x <- afrDat$xvar
y <- afrDat$obs
plot(x, y, type="n", las=1, bty="l")
mtext(text = "Ruggedness", side=1, line = 2, cex=1)
mtext(text = "log(GDP)", side=2, line = 2.2, cex=1)

# plot uncertainty interval in mu as a polygon
polygon(x=c(x, rev(x)), y=c(afrHDI[1,], 
  rev(afrHDI[2,])), col="#50505080", border="black")

# plot the data points and mean regression line
points(x, y, pch=1, col="blue")
lines(afrMean~x, col="black", lwd=2)
text(3, 9.7, "Africa", font=2)

### NONAFRICA
nHDI <- apply(nMu,2, HDI, credMass=0.95)
nMean <- colMeans(nMu)

# Make an empty plot
x <- nafrDat$xvar
y <- nafrDat$obs
plot(x, y, type="n", las=1, bty="l")
mtext(text = "Ruggedness", side=1, line = 2, cex=1)

# plot uncertainty interval in mu as a polygon
polygon(x=c(x, rev(x)), y=c(nHDI[1,], 
  rev(nHDI[2,])), col="#50505080", border="black")

# plot the data points and mean regression line
points(x, y, pch=1, col="black")
lines(nMean~x, col="black", lwd=2)
text(3, 10.9, "not Africa", font=2)
```

It might make sense that ruggedness would be associated with poor countries. Rugged terrain makes travel challenging, which might impede the movement of goods and services to market, thus depressing wealth. 
  
But why is the situation reversed in Africa?

One hypothesis is that rugged regions served as a barrier to the slave trade, which was predominately based on the coasts. Those regions continue to suffer economically in many regards. 
    
Regardless, irregardless even, of the reversal between African and non-African countries, how do we model this? Here we are cheating by splitting the data in two, and there are obvious drawbacks to that.

  1. There are some parameters that are independent of African identity (e.g., $\sigma$). 
   
    * By doing a no-pooling model, we are decreasing the accuracy of the estimate for those parameters and making two less-accurate estimates rather than pooling all the evidence into one.
 
    * also make a strong assumption that the variance differs between African and non-African countries.

  2. We are not making any probability statements about the difference between African and non-African countries because we are not including that variable in the model. 
  
    * Assuming there is no uncertainty in discriminating between African/non-African countries.
    
  3. Later on, we may want to use information criteria to compare models that treat all the data as belonging to one posterior distribution as opposed to a model that allows different slopes. 
  
  * We have to include all the data in a model to do so.  
    

\subsection*{Adding a dummy variable}    
So let's add Africa as an indicator variable and use model `13.multMod.stan`. How does singling out African nations affect our conclusions? 

```{r, message=FALSE, warning=FALSE, cache=TRUE, verbose=FALSE}
# African linear regression
X <- cbind(rugged$rugged, rugged$africa)
fullDat <- list(nObs=nrow(rugged), nVar=ncol(X), obs=log(rugged$GDP), X=X, 
  aMu=0, aSD=20, bMu=0, bSD=1, sigmaSD=10)

fullMod <- stan(file="13.multMod.stan", data=fullDat, iter=2000,
 chains=4, seed=867.5309)
mu <- as.matrix(fullMod, "mu")
muHDI <- apply(mu, 2, HDI, credMass=0.95)
muMn <- colMeans(mu)
```  

```{r, fig.height=2.6, fig.width=4}
par(mar=c(3,3.2,0.1,0.5))
par(mfrow=c(1,1))
### AFRICA
# Mean & HDI 
afrHDI <- muHDI[,rugged$africa==1]
afrMean <- muMn[rugged$africa==1]

### not AFRICA
# Mean & HDI
nHDI <- muHDI[,rugged$africa==0]
nMean <- muMn[rugged$africa==0]

# Make an empty plot
x <- nafrDat$xvar
y <- nafrDat$obs
plot(x, y, type="n", las=1, bty="l", ylim=c(6,11))
mtext(text = "Ruggedness", side=1, line = 2, cex=1)
mtext(text = "log(GDP)", side=2, line = 2.2, cex=1)

# plot uncertainty interval in mu as a polygon
polygon(x=c(x, rev(x)), y=c(nHDI[1,], 
  rev(nHDI[2,])), col="#50505080", border="black")

# plot the data points and mean regression line
points(x, y, pch=1, col="black")
lines(nMean~x, col="black", lwd=2)

### AFRICA
x <- afrDat$xvar
y <- afrDat$obs
# plot uncertainty interval in mu as a polygon
polygon(x=c(x, rev(x)), y=c(afrHDI[1,], 
  rev(afrHDI[2,])), col="#88CCEE80", border="#88CCEE")

# plot the data points and mean regression line
points(x, y, pch=1, col="blue")
lines(afrMean~x, col="blue", lwd=2)
```
According to this figure, there is a slightly negative relationship between GDP and ruggedness overall. 
  
  * Including the dummy variable for Africa has allowed the model to predict a lower mean GDP for African nations relative to non-African nations. 

  * But the slopes are parallel! What's going on?
  
\subsection*{Adding a linear interaction}
Unsurprisingly perhaps, we need an interaction effect. 

The likelihood function for the previous model was essentially: 
\begin{align}
  obs_i   &\sim \mathrm{Normal}(\mu_i, \sigma)  \nonumber  \\ 
  \mu_i   &= \alpha + \beta_R R_{i} + \beta_A A_{i} \nonumber
\end{align}
where $R$ is `rugged` and $A$ is `africa`. 

This linear model is constructed by specifying the mean $\mu$ as a linear function of new parameters and data. 

Interactions will extend this approach. Now we want the relationship between $obs$ and $R$ to vary as a function of $A$. 
  
In the previous model, this relationship was measured by $\beta_R$.
 
  * What we want to do is make $\beta_R$ a linear function itself---one that includes $A$. 

\begin{align}
  obs_i     &\sim \mathrm{Normal}(\mu_i, \sigma)  \nonumber  \\ 
  \mu_i     &= \alpha + \gamma_i R_{i} + \beta_A A_{i} \nonumber \\
  \gamma_i  &= \beta_R + \beta_{AR} A_i \nonumber
\end{align}    

Now our Bayesian model has two linear models in it, but it's essentially the same as every regression model thus far.
 
  1. The first line is the same Gaussian likelihood we all know and love.
 
  2. The second line is the same additive definition of $\mu_i$.
 
  3. The third line uses $\gamma$ as a placeholder for our new linear function that defines the slope between `log(GDP)` and `rugged`.
  
    * $\gamma_i$ is the linear interaction effect of ruggedness and African nations
     
$\gamma_i$ explicitly models the hypothesis that the slope between `GDP` and ruggedness is \emph{conditional} on whether a nation is on the African continent with $\beta_{AR}$ describing the strength of that dependence.

  * If $\beta_{AR}=0$, then we get our original likelihood function back. 
   
    + For any nation not in Africa, $A_i=0$ and so $\beta_{AR}$ has no effect.
 
  * If $\beta_{AR}>1$, African nations have a more positive slope between GDP and ruggedness. 
 
  * if $\beta_{AR}<1$, African nations have a more negative slope


We could also rewrite this equation using the conventional notation by substituting in $\gamma_i$:
\begin{align}
  \gamma_i  &= \beta_R + \beta_{AR} A_i \nonumber \\
  \mu_i     &= \alpha + \gamma_i R_{i} + \beta_A A_{i} \nonumber \\
            &= \alpha + (\beta_R + \beta_{AR} A_i) R_{i} + \beta_A A_{i} \nonumber \\
            &= \alpha + \beta_R R_i + \beta_{AR} A_iR_{i} + \beta_A A_{i}. \nonumber
\end{align}    

The former is more explicit and understanding it will be key to understanding (and building) more complex hierarchical models later. 

The latter likelihood function is much easier to code though. There are about 5 different ways to code the first model. The easiest is to do the following:

```{r, eval=FALSE}
data {
  int<lower=0> nObs;
  vector[nObs] obs;
  vector[nObs] R;
  vector[nObs] A;
  real<lower=0> aMu;      // mean of prior alpha
  real<lower=0> aSD;      // SD of prior alpha
  real<lower=0> bMu;      // mean of prior betas
  real<lower=0> bSD;      // SD of prior beta
  real<lower=0> sigmaSD;  // scale for sigma
}

parameters {
  real alpha;
  real betaR;
  real betaA;
  real betaAR;
  real<lower=0> sigma;
}

transformed parameters {
  vector[nObs] mu;
  vector[nObs] gamma;
  
  gamma = betaR + betaAR*A;
  // elementwise multiplication (.*)!
  mu = alpha + gamma .* R + betaA*A; 
}

model {
  alpha ~ normal(aMu, aSD);
  betaR ~  normal(bMu, bSD);
  betaA ~  normal(bMu, bSD);
  betaAR ~  normal(bMu, bSD);
  sigma ~ cauchy(0, sigmaSD);

  obs ~ normal(mu, sigma);
}

```

```{r engine = 'cat', engine.opts = list(file = "13.intrxnMod.stan", lang = "stan"), echo=FALSE}
data {
  int<lower=0> nObs;
  vector[nObs] obs;
  vector[nObs] R;
  vector[nObs] A;
  real<lower=0> aMu;      // mean of prior alpha
  real<lower=0> aSD;      // SD of prior alpha
  real<lower=0> bMu;      // mean of prior betas
  real<lower=0> bSD;      // SD of prior beta
  real<lower=0> sigmaSD;  // scale for sigma
}

parameters {
  real alpha;
  real betaR;
  real betaA;
  real betaAR;
  real<lower=0> sigma;
}

transformed parameters {
  vector[nObs] mu;
  vector[nObs] gamma;
  
  gamma = betaR + betaAR*A;
  // elementwise multiplication (.*)!
  mu = alpha + gamma .* R + betaA*A; 
}

model {
  alpha ~ normal(aMu, aSD);
  betaR ~  normal(bMu, bSD);
  betaA ~  normal(bMu, bSD);
  betaAR ~  normal(bMu, bSD);
  sigma ~ cauchy(0, sigmaSD);

  obs ~ normal(mu, sigma);
}

```

Could also do the following:
```{r, eval=FALSE}
transformed parameters {
  vector[nObs] mu;
  vector[nObs] gamma;
  
  gamma = betaR + betaAR*A;
  mu = alpha + to_vector(gamma * R') + betaA*A;
}
```

The ' symbol means transpose and turns a `nObs` $\times$ 1 `vector` into a 1 $\times$ `nObs` vector for proper matrix multiplication (and results in a `nObs` $\times$ 1) output matrix). 
 
 
 * Through the vagaries of Stan, you can't add together matrices and vectors. Therefore we coerce `gamma` $\times$ `R` into a vector using `to_vector()`.
 
 * Alternatively we could just define `R` as a `row_vector` in the `data` block and skip the transpose.

Regardless of which model we use, we get the same results. If we run either model 

```{r, message=FALSE, warning=FALSE, cache=TRUE, verbose=FALSE}
# African linear regression
X <- model.matrix(~rugged*africa, data=rugged)[,2:4]

intDat <- list(nObs=nrow(rugged), obs=log(rugged$GDP),
  R=X[,"rugged"], A=X[,"africa"], aMu=0, aSD=20, bMu=0, bSD=1, sigmaSD=10)

intxnMod <- stan(file="13.intrxnMod.stan", data=intDat, iter=2000,
 chains=4, seed=867.5309)
mu <- as.matrix(intxnMod, "mu")
muHDI <- apply(mu, 2, HDI, credMass=0.95)
muMn <- colMeans(mu)
```

```{r, fig.height=2.6, fig.width=7, echo=FALSE}
par(mar=c(3,3.2,0.1,0.5))
par(mfrow=c(1,2))
### AFRICA
# Mean & HDI
afrHDI <- muHDI[,rugged$africa==1]
afrMean <- muMn[rugged$africa==1]

### not AFRICA
# Mean & HDI
nHDI <- muHDI[,rugged$africa==0]
nMean <- muMn[rugged$africa==0]

### AFRICA
x <- afr$rugged
y <- log(afr$GDP)
plot(x, y, type="n", las=1, bty="l")
mtext(text = "Ruggedness", side=1, line = 2, cex=1)
mtext(text = "log(GDP)", side=2, line = 2.2, cex=1)

# plot uncertainty interval in mu as a polygon
polygon(x=c(x, rev(x)), y=c(afrHDI[1,],
  rev(afrHDI[2,])), col="#50505080", border="black")

# plot the data points and mean regression line
points(x, y, pch=1, col="blue")
lines(afrMean~x, col="black", lwd=2)

### NOT AFRICA
# Make an empty plot
x <- nafr$rugged
y <- log(nafr$GDP)
plot(x, y, type="n", las=1, bty="l")
mtext(text = "Ruggedness", side=1, line = 2, cex=1)

# plot uncertainty interval in mu as a polygon
polygon(x=c(x, rev(x)), y=c(nHDI[1,],
  rev(nHDI[2,])), col="#50505080", border="black")

# plot the data points and mean regression line
points(x, y, pch=1, col="black")
lines(nMean~x, col="black", lwd=2)
```

we find a positive relationship between `log(GDP)` and `ruggedness` for African nations and a negative relationship for non-African nations.

\subsection*{Interpreting interaction terms}
Interpreting interaction terms is not easy

* Plotting out the results is usually best for model inference.

* However, there are times when interpretation of the parameter estimates themselves is of value.

There are two reasons why interpreting tables of parameter estimates from models with interaction terms is challenging:

  1. *Adding an interaction to the model changes parameter meanings.* Usually, the distribution of a ``main effect'' coefficient in an interaction model can not be directly compared to a term of the same name in a non-interaction model.

  2. *Interpreting tables of interaction effects require thinking about parameter covariance.* This is a lot harder when the influence of a predictor depends on multiple parameters.

\subsection*{Adding an interaction to the model changes parameter meanings:}

In a simple linear regression without interaction terms, each predictor variable is independent and directly measures that variable's influence.
  
  * Not so for models with interaction terms

If we look at our likelihood function again, 
$$
\begin{aligned}
  obs_i     &\sim \mathrm{Normal}(\mu_i, \sigma)  \nonumber  \\ 
  \mu_i     &= \alpha + \gamma_i R_{i} + \beta_A A_{i} \nonumber \\
  \gamma_i  &= \beta_R + \beta_{AR} A_i \nonumber
\end{aligned}
$$

a change in $\mu_i$ is dependent on a unit change in $R_i$ is governed by $\gamma_i$. 
 
  * $\gamma_i$ is a function of $\beta_R$, $\beta_{AR}$, and $A_i$; we need to know all three to interpret the effect of $R_i$ on the outcome. 
  
    * Only when $A_i=0$ can we interpret the slope $\beta_R$ because then $\gamma_i=\beta_R$.

Practically, this means interpreting tables of the estimates requires some math. If we want to estimate the effect of ruggedness on `log(GDP)` within Africa
```{r}
round(summary(intxnMod, pars=c("alpha", "betaR", "betaA",
  "betaAR"), probs = c(0.025, 0.5, 0.975))$summary,2)
```

If we want to estimate the effect of ruggedness on `log(GDP)` within Africa,
$$
\begin{aligned}
  \gamma = \beta_R + \beta_{AR}(1) = -0.18 + 0.35 = 0.17.
\end{aligned}
$$
Outside of Africa, 
$$
\begin{aligned}
  \gamma = \beta_R + \beta_{AR}(0) = -0.18 = -0.18,
\end{aligned}
$$

so the relationship is essentially reversed. 

\subsection*{Interpreting tables of interaction effects require thinking about parameter covariance:}

But those are only point estimates of the marginal values. If we really want to compare the effects between African and non-African countries, we have to consider the whole posterior distribution:
```{r}
slopes <- as.matrix(intxnMod, pars=c("betaR", "betaAR"))
gammaA <- slopes[,"betaR"] + slopes[,"betaAR"]*1
gammaNA <- slopes[,"betaR"] + slopes[,"betaAR"]*0
mean(gammaA)
mean(gammaNA)
```
The means are almost identical to those above.

```{r,fig.height=2.6, fig.width=7, echo=FALSE}
par(mar=c(3,3.2,0.1,0.5))
par(mfrow=c(1,2))
plot(density(gammaNA), main="", xlim=c(-0.5,0.6), col="black",
  lwd=2, las=1)
lines(density(gammaA), col="blue",lwd=2)
mtext(text = expression(gamma), side=1, line = 2, cex=1.2)
mtext(text = expression(p(gamma)), side=2, line = 1.9, cex=1.2)
text(0.3,4, "Africa")
text(0.05, 5, "Not Africa")
plot(density(gammaA-gammaNA), main="", xlim=c(-0.2,0.8),
  col="red",lwd=2, lty=1, las=1)
mtext(text = expression(paste(Delta," ", gamma)), side=1, line = 2, cex=1.2)
```

But we can also plot the full distributions together, or the difference in the distributions. Note that the proportion of the differences less than zero is only `r sum(gammaA-gammaNA < 0)/nrow(slopes)`

* much less than the overlap of the marginal distributions suggests. 
